{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd82f807029bb81b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T18:49:55.518005Z",
     "start_time": "2025-07-28T18:49:55.506606Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from utilities import plot_prediction_area_curves, get_pa_intersection\n",
    "import time\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59052a54a3f23630",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T18:49:55.824676Z",
     "start_time": "2025-07-28T18:49:55.810873Z"
    }
   },
   "outputs": [],
   "source": [
    "class MCDropoutNet(nn.Module):\n",
    "    def __init__(self, input_dim: int, dropout_rate: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, 32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=self.dropout_rate) \n",
    "        \n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(p=self.dropout_rate)\n",
    "        \n",
    "        self.fc_out = nn.Linear(32, 1) \n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x) \n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x) \n",
    "        \n",
    "        logits = self.fc_out(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aed0ed487d1a1743",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T18:49:56.671384Z",
     "start_time": "2025-07-28T18:49:56.663563Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_dropout_active(model, active: bool):\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Dropout):\n",
    "            if active:\n",
    "                module.train() \n",
    "            else:\n",
    "                module.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c357675f4d6f9a42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T18:49:57.284094Z",
     "start_time": "2025-07-28T18:49:57.269222Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_mc_dropout_predictions(\n",
    "    model: MCDropoutNet, \n",
    "    data_loader: DataLoader, \n",
    "    num_mc_samples: int, \n",
    "    device: str\n",
    "):\n",
    "    model.to(device)\n",
    "    set_dropout_active(model, True) \n",
    "\n",
    "    all_mc_probs_stacked_batches = [] \n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for x_batch, _ in tqdm(data_loader, desc=\"MC Dropout Inference\"): \n",
    "            x_batch = x_batch.to(device)\n",
    "            \n",
    "            batch_mc_logits_samples = [] \n",
    "            for _ in range(num_mc_samples):\n",
    "                logits_sample = model(x_batch)\n",
    "                batch_mc_logits_samples.append(logits_sample)\n",
    "            \n",
    "            batch_mc_logits_stacked = torch.stack(batch_mc_logits_samples)\n",
    "            batch_mc_probs_stacked = torch.sigmoid(batch_mc_logits_stacked)\n",
    "            \n",
    "            all_mc_probs_stacked_batches.append(batch_mc_probs_stacked.cpu())\n",
    "\n",
    "    all_mc_probs_stacked_tensor = torch.cat(all_mc_probs_stacked_batches, dim=1)\n",
    "\n",
    "    mean_probs = all_mc_probs_stacked_tensor.mean(dim=0).squeeze().numpy() \n",
    "    pred_variances = all_mc_probs_stacked_tensor.var(dim=0).squeeze().numpy() \n",
    "    pred_labels = (mean_probs > 0.5).astype(int)\n",
    "\n",
    "    set_dropout_active(model, False) \n",
    "    return mean_probs, pred_variances, pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de0b3d05684352c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T18:49:58.255191Z",
     "start_time": "2025-07-28T18:49:58.247019Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset\n",
    "train_features_path: str = './data/dataset_train.pt'\n",
    "train_labels_path: str = './data/mineral_train.pt'\n",
    "test_features_path: str = './data/dataset_test.pt'\n",
    "test_labels_path: str = './data/mineral_test.pt'\n",
    "scaler_path: str = './data/scaler.pkl' \n",
    "output_dir_for_saving: str = \"./mc_dropout_mineral_outputs_run\" \n",
    "\n",
    "random_state: int = 42\n",
    "batch_size: int = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55b781075461f292",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T17:56:52.546420Z",
     "start_time": "2025-07-28T17:56:52.494457Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = random_state\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if not os.path.exists(output_dir_for_saving): \n",
    "    os.makedirs(output_dir_for_saving)\n",
    "    print(f\"Created output directory: {output_dir_for_saving}\")\n",
    "else:\n",
    "    print(f\"Output directory already exists: {output_dir_for_saving}\")"
   ],
   "id": "fab40cc892836fee"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c42bcabf1ff28f81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T17:56:53.415185Z",
     "start_time": "2025-07-28T17:56:52.557166Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_np = torch.load(train_features_path).numpy()\n",
    "y_train_np = torch.load(train_labels_path).numpy().ravel()\n",
    "X_test_np = torch.load(test_features_path).numpy()\n",
    "y_test_np = torch.load(test_labels_path).numpy().ravel() "
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Applying ADASYN\n",
    "adasyn = ADASYN(random_state=RANDOM_SEED) \n",
    "X_train_np, y_train_np = adasyn.fit_resample(X_train_np, y_train_np)\n",
    "\n",
    "print(f\"After ADASYN - training set size: {X_train_np.shape[0]}\")\n",
    "print(f\"After ADASYN - training class distribution: {np.bincount(y_train_np.astype(int))}\")"
   ],
   "id": "ee176d52907f8a8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_dataset = TensorDataset(torch.from_numpy(X_train_np), torch.from_numpy(y_train_np).unsqueeze(1))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n",
    "                          pin_memory=device.type == 'cuda', num_workers=2 if device.type=='cuda' else 0)\n",
    "test_dataset = TensorDataset(torch.from_numpy(X_test_np), torch.from_numpy(y_test_np).unsqueeze(1))\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, \n",
    "                         pin_memory=device.type == 'cuda', num_workers=2 if device.type=='cuda' else 0)\n",
    "\n",
    "input_dim = X_train_np.shape[1] \n",
    "\n",
    "print(f\"Data preparation complete. Input dimension: {input_dim}\")\n",
    "print(f\"Train loader size: {len(train_loader)} batches\")\n",
    "print(f\"Test loader size: {len(test_loader)} batches\")"
   ],
   "id": "9b0ab46c40a09aa4"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8aab5cbc7b246f82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T17:57:07.725080Z",
     "start_time": "2025-07-28T17:57:07.718971Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs_train: int = 100\n",
    "learning_rate_train: float = 1e-3\n",
    "dropout_rate_model: float = 0.1 \n",
    "print_every_epoch_train: int = 1\n",
    "num_mc_final_eval_train: int = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "159953aa2863eff0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T17:57:11.767754Z",
     "start_time": "2025-07-28T17:57:07.728049Z"
    }
   },
   "outputs": [],
   "source": [
    "model_mc_dropout = MCDropoutNet(input_dim, dropout_rate=dropout_rate_model).to(device) \n",
    "optimizer = optim.Adam(model_mc_dropout.parameters(), lr=learning_rate_train) \n",
    "criterion = nn.BCEWithLogitsLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed11e9c8ab0d04d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T17:57:11.774944Z",
     "start_time": "2025-07-28T17:57:11.769699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC Dropout - Total trainable parameters: 6,657\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model_mc_dropout.parameters() if p.requires_grad)\n",
    "print(f\"MC Dropout - Total trainable parameters: {total_params:,}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "### TRAINING\n",
    "train_losses_epoch, train_errors_epoch, test_errors_epoch, epochs_list = [], [], [], []\n",
    "epoch_durations_list = [] \n",
    "\n",
    "process = psutil.Process(os.getpid())\n",
    "overall_peak_ram_mb = 0 # Tracks the peak across the entire run\n",
    "\n",
    "overall_training_start_time = time.time()\n",
    "for epoch in range(num_epochs_train):\n",
    "    epoch_start_time = time.time()\n",
    "    model_mc_dropout.train() \n",
    "    \n",
    "    # Reset the peak tracker for each epoch\n",
    "    peak_ram_in_epoch_mb = 0\n",
    "    \n",
    "    epoch_total_loss, correct_train, total_train = 0, 0, 0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs_train}\")\n",
    "    \n",
    "    for x_batch, y_batch in pbar:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device) \n",
    "        optimizer.zero_grad() \n",
    "        logits = model_mc_dropout(x_batch)\n",
    "        loss = criterion(logits, y_batch) \n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        epoch_total_loss += loss.item()\n",
    "        probs = torch.sigmoid(logits); predicted_train = (probs > 0.5).float() \n",
    "        total_train += y_batch.size(0); correct_train += (predicted_train == y_batch).sum().item()\n",
    "        pbar.set_postfix({\"Loss\": loss.item()})\n",
    "\n",
    "        # RAM after each batch and update both epoch and overall peaks\n",
    "        current_ram_mb = process.memory_info().rss / (1024 ** 2)\n",
    "        peak_ram_in_epoch_mb = max(peak_ram_in_epoch_mb, current_ram_mb)\n",
    "        overall_peak_ram_mb = max(overall_peak_ram_mb, current_ram_mb)\n",
    "\n",
    "    avg_epoch_loss = epoch_total_loss / len(train_loader)\n",
    "    train_accuracy = correct_train / total_train if total_train > 0 else 0\n",
    "    train_error = (1 - train_accuracy) * 100\n",
    "    print(f\"Epoch {epoch+1} - Avg Loss: {avg_epoch_loss:.4f}, Train Err: {train_error:.2f}%\") \n",
    "    \n",
    "    current_epoch_duration = time.time() - epoch_start_time\n",
    "    epoch_durations_list.append(current_epoch_duration)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} completed in {current_epoch_duration:.2f} seconds. Peak RAM in Epoch: {peak_ram_in_epoch_mb:.2f} MB\")\n",
    "\n",
    "print(f\"\\n--- MC Dropout Model Training Loop Complete ---\")\n",
    "print(f\"Total training duration for {num_epochs_train} epochs: {time.time() - overall_training_start_time:.2f} seconds.\")\n",
    "\n",
    "if epoch_durations_list: \n",
    "    avg_time_per_epoch = np.mean(epoch_durations_list)\n",
    "    std_time_per_epoch = np.std(epoch_durations_list)\n",
    "    print(f\"MC Dropout - Average time per epoch: {avg_time_per_epoch:.2f} Â± {std_time_per_epoch:.2f} seconds\")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    peak_vram_mb = torch.cuda.max_memory_allocated() / (1024**2) \n",
    "    print(f\"MC Dropout - Peak VRAM (GPU) used during training: {peak_vram_mb:.2f} MB\")\n",
    "else:\n",
    "    print(f\"MC Dropout - Overall Peak RAM (System) used during training: {overall_peak_ram_mb:.2f} MB\")"
   ],
   "id": "b5d124c55f09e371"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Error plot \n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "plt.plot(epochs_list, train_errors_epoch, linestyle='-', marker='', label='Training Error')\n",
    "\n",
    "valid_test = ~np.isnan(test_errors_epoch)\n",
    "if valid_test.any():\n",
    "    plt.plot(\n",
    "        np.array(epochs_list)[valid_test],\n",
    "        np.array(test_errors_epoch)[valid_test],\n",
    "        linestyle='-', marker='',\n",
    "        label='Test Error'\n",
    "    )\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error Rate (%)')\n",
    "plt.title('MC Dropout Error Rate vs Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "outfile = os.path.join(output_dir_for_saving, 'mc_dropout_error_rate_vs_epoch.png')\n",
    "plt.tight_layout()\n",
    "plt.savefig(outfile)\n",
    "plt.show()"
   ],
   "id": "481ececfad4874cf"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5193b97d2bf88cf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T18:15:10.517027Z",
     "start_time": "2025-07-28T18:15:10.490158Z"
    }
   },
   "outputs": [],
   "source": [
    "model_save_path = os.path.join(output_dir_for_saving, f'mc_dropout_mineral_model_ep{num_epochs_train}_seed{RANDOM_SEED}.pth')\n",
    "torch.save(model_mc_dropout.state_dict(), model_save_path)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "true_labels_test_list = []\n",
    "for _, y_batch_test in test_loader: \n",
    "    true_labels_test_list.append(y_batch_test.cpu().numpy().flatten())\n",
    "true_labels_np = np.concatenate(true_labels_test_list)\n",
    "\n",
    "mean_probabilities, predictive_variances, predicted_labels = get_mc_dropout_predictions(\n",
    "    model_mc_dropout, test_loader, num_mc_final_eval_train, device)"
   ],
   "id": "786d2a4a459043c4"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d32042aa1a5c20f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T18:15:34.529306Z",
     "start_time": "2025-07-28T18:15:34.390651Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(os.path.join(output_dir_for_saving, 'mc_dropout_true_labels.npy'), true_labels_np)\n",
    "np.save(os.path.join(output_dir_for_saving, 'mc_dropout_mean_probs.npy'), mean_probabilities)\n",
    "np.save(os.path.join(output_dir_for_saving, 'mc_dropout_pred_labels.npy'), predicted_labels)\n",
    "np.save(os.path.join(output_dir_for_saving, 'mc_dropout_pred_variances.npy'), predictive_variances)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "final_test_error_rate = (1.0 - np.sum(predicted_labels == true_labels_np) / len(true_labels_np)) * 100 if len(true_labels_np) > 0 else 0.0\n",
    "fpr, tpr, _ = roc_curve(true_labels_np, mean_probabilities) \n",
    "roc_auc_score = auc(fpr, tpr) if len(fpr) > 1 and len(tpr) > 1 else 0.0\n",
    "print(f\"\\nSummary from Final MC Dropout Test Outputs:\")\n",
    "print(f\"  Final Test Error Rate: {final_test_error_rate:.2f}%\")\n",
    "print(f\"  Final ROC AUC Score: {roc_auc_score:.4f}\")"
   ],
   "id": "57e0e9fb68c694f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "eb067b2748c88bca"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d549da5df5a14fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T18:15:34.708773Z",
     "start_time": "2025-07-28T18:15:34.631446Z"
    }
   },
   "outputs": [],
   "source": [
    "output_dir = \"./MC_mineral_outputs\" \n",
    "\n",
    "true_labels_loaded = np.load(os.path.join(output_dir_for_saving, 'mc_dropout_true_labels.npy'))\n",
    "mean_probs_loaded = np.load(os.path.join(output_dir_for_saving, 'mc_dropout_mean_probs.npy'))\n",
    "pred_labels_loaded = np.load(os.path.join(output_dir_for_saving, 'mc_dropout_pred_labels.npy'))\n",
    "pred_variances_loaded = np.load(os.path.join(output_dir_for_saving, 'mc_dropout_pred_variances.npy'))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ROC plot\n",
    "fpr_loaded, tpr_loaded, _ = roc_curve(true_labels_loaded, mean_probs_loaded)\n",
    "roc_auc_loaded = auc(fpr_loaded, tpr_loaded)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr_loaded, tpr_loaded, color='Orange', lw=2, label=f'MC Dropout ROC (AUC = {roc_auc_loaded:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "font_size = 14\n",
    "\n",
    "plt.xlabel('False positive rate', fontsize=font_size, labelpad=10)\n",
    "plt.ylabel('True positive rate', fontsize=font_size, labelpad=10)\n",
    "#plt.title('MC Dropout ROC Curve', fontsize=font_size)\n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=font_size)\n",
    "\n",
    "plt.legend(loc=\"lower right\", fontsize=font_size)\n",
    "\n",
    "#.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'mc_dropout_roc_curve_final.pdf'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "325f82449e971a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Confusion matrix\n",
    "cm_loaded = confusion_matrix(true_labels_loaded, pred_labels_loaded)\n",
    "\n",
    "display_loaded = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm_loaded,\n",
    "    display_labels=['Barren', 'Mineral']\n",
    ")\n",
    "\n",
    "fig_cm_loaded, ax_cm_loaded = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "display_loaded.plot(\n",
    "    ax=ax_cm_loaded,\n",
    "    cmap=plt.cm.Blues,\n",
    "    values_format='d'    \n",
    ")\n",
    "\n",
    "font_size = 14\n",
    "ax_cm_loaded.set_xlabel('Predicted label', fontsize=font_size, labelpad=10)\n",
    "ax_cm_loaded.set_ylabel('True label',      fontsize=font_size, labelpad=10)\n",
    "ax_cm_loaded.tick_params(axis='both', which='major', labelsize=font_size)\n",
    "\n",
    "cbar = ax_cm_loaded.images[0].colorbar\n",
    "if cbar is not None:\n",
    "    cbar.ax.ticklabel_format(style='plain')         \n",
    "    cbar.ax.tick_params(labelsize=font_size)\n",
    "    \n",
    "for text in ax_cm_loaded.texts:\n",
    "    text.set_fontsize(font_size)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'mc_dropout_confusion_matrix_final.pdf'),\n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "id": "a77d643e8ed3e4d6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21083101cd9b10eb",
   "metadata": {},
   "outputs": [],
   "source": "print(classification_report(true_labels_loaded, pred_labels_loaded, target_names=['Class 0', 'Class 1'], zero_division=0))"
  },
  {
   "cell_type": "markdown",
   "id": "bb194115dbd4e48b",
   "metadata": {},
   "source": [
    "### Evaluation on Noisy Data"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_features_path = './data/dataset_test.pt'\n",
    "test_labels_path = './data/mineral_test.pt'\n",
    "scaler_path = './data/scaler.pkl'\n",
    "\n",
    "X_test_np = torch.load(test_features_path).numpy()\n",
    "true_labels_np = torch.load(test_labels_path).numpy().ravel()\n",
    "\n",
    "clean_test_dataset = TensorDataset(torch.from_numpy(X_test_np), torch.from_numpy(true_labels_np))\n",
    "clean_test_loader = DataLoader(clean_test_dataset, batch_size=128, shuffle=False)\n",
    "mean_probs_clean, _, _ = get_mc_dropout_predictions(\n",
    "    model_mc_dropout, clean_test_loader, num_mc_final_eval_train, device)\n",
    "fpr_clean, tpr_clean, _ = roc_curve(true_labels_np, mean_probs_clean)\n",
    "roc_auc_score = auc(fpr_clean, tpr_clean) # This defines the variable\n",
    "\n",
    "np.random.seed(42) \n",
    "noise_level = 0.1\n",
    "noise = np.random.normal(0, noise_level, X_test_np.shape).astype(np.float32)\n",
    "X_test_noisy = X_test_np + noise\n",
    "\n",
    "noisy_test_dataset = TensorDataset(torch.from_numpy(X_test_noisy), torch.from_numpy(true_labels_np))\n",
    "noisy_test_loader = DataLoader(noisy_test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "mean_probs_noisy, _, _ = get_mc_dropout_predictions(\n",
    "    model_mc_dropout, noisy_test_loader, num_mc_final_eval_train, device)\n",
    "\n",
    "fpr_noisy, tpr_noisy, _ = roc_curve(true_labels_np, mean_probs_noisy)\n",
    "roc_auc_noisy = auc(fpr_noisy, tpr_noisy)\n",
    "\n",
    "print(f\"\\nOriginal ROC AUC on clean data: {roc_auc_score:.4f}\")\n",
    "print(f\"ROC AUC on noisy data:         {roc_auc_noisy:.4f}\")\n",
    "print(f\"Performance Drop:               {roc_auc_score - roc_auc_noisy:.4f}\")"
   ],
   "id": "dc8b32d1aa0f36a6"
  },
  {
   "cell_type": "markdown",
   "id": "e3616d6b9f03dd84",
   "metadata": {},
   "source": [
    "### Total Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c7ba39626089793",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T17:27:45.356545Z",
     "start_time": "2025-06-03T17:27:45.352466Z"
    }
   },
   "outputs": [],
   "source": [
    "TOTAL_FEATURES_PATH_MC   = \"./data/total_train.pt\" \n",
    "SCALER_PATH_MC           = \"./data/scaler.pkl\"     \n",
    "\n",
    "MODEL_SAVE_PATH_MC      = os.path.join(output_dir_for_saving, f'mc_dropout_mineral_model_ep{num_epochs_train}_seed{RANDOM_SEED}.pth')\n",
    "PRED_BATCH_SIZE_MC       = 1024\n",
    "NUM_MC_SAMPLES_TOTAL_MC  = 20 \n",
    "DROPOUT_RATE_FOR_TOTAL_EVAL = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55c94e90b4a88133",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T17:27:45.366445Z",
     "start_time": "2025-06-03T17:27:45.357837Z"
    }
   },
   "outputs": [],
   "source": [
    "MC_TOTAL_MEAN_PROBS_PATH = os.path.join(output_dir_for_saving, \"mc_dropout_total_mean_probs.npy\")\n",
    "MC_TOTAL_PRED_VAR_PATH = os.path.join(output_dir_for_saving, \"mc_dropout_total_pred_variances.npy\")\n",
    "MC_GEOPACKAGE_OUTPUT_PATH = os.path.join(output_dir_for_saving, \"mc_dropout_total_predictions_mpm.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7363f4895a384f32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T17:27:53.300235Z",
     "start_time": "2025-06-03T17:27:45.368134Z"
    }
   },
   "outputs": [],
   "source": [
    "X_total_mc = torch.load(TOTAL_FEATURES_PATH_MC).numpy().astype(np.float32)\n",
    "# scaler_mc  = pickle.load(open(SCALER_PATH_MC, \"rb\"))\n",
    "# X_total_mc = scaler_mc.transform(X_total_mc).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e6151b14644b3e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T17:27:53.321563Z",
     "start_time": "2025-06-03T17:27:53.308297Z"
    }
   },
   "outputs": [],
   "source": [
    "dummy_y_mc = np.zeros((X_total_mc.shape[0],), dtype=np.float32) \n",
    "full_ds_mc  = TensorDataset(torch.from_numpy(X_total_mc), torch.from_numpy(dummy_y_mc).unsqueeze(1)) \n",
    "loader_full_mc = DataLoader(\n",
    "    full_ds_mc,\n",
    "    batch_size=PRED_BATCH_SIZE_MC,\n",
    "    shuffle=False,\n",
    "    pin_memory=device.type == 'cuda', \n",
    "    num_workers=2 if device.type == 'cuda' else 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db31ba900d89d103",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T17:27:53.363469Z",
     "start_time": "2025-06-03T17:27:53.322923Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_total_eval  = MCDropoutNet(input_dim, dropout_rate=DROPOUT_RATE_FOR_TOTAL_EVAL).to(device)\n",
    "model_total_eval.load_state_dict(torch.load(MODEL_SAVE_PATH_MC, map_location=device))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mean_probs_full_mc, var_probs_full_mc, _ = get_mc_dropout_predictions(\n",
    "    model_total_eval, loader_full_mc, NUM_MC_SAMPLES_TOTAL_MC, device)"
   ],
   "id": "86064734665c96b2"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84c126fff180b779",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T17:28:11.916374Z",
     "start_time": "2025-06-03T17:28:11.710960Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(MC_TOTAL_MEAN_PROBS_PATH, mean_probs_full_mc)\n",
    "np.save(MC_TOTAL_PRED_VAR_PATH, var_probs_full_mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "785f48320aeb5ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T17:44:05.135925Z",
     "start_time": "2025-06-03T17:28:11.919902Z"
    }
   },
   "outputs": [],
   "source": [
    "gdf_mc = gpd.read_file(\"data/datacube_mpm.gpkg\")\n",
    "n_mc = min(len(gdf_mc), len(mean_probs_full_mc)) \n",
    "gdf_mc = gdf_mc.iloc[:n_mc].copy() \n",
    "\n",
    "gdf_mc[\"mc_mean_prob\"] = mean_probs_full_mc[:n_mc]\n",
    "gdf_mc[\"mc_pred_var\"]  = var_probs_full_mc[:n_mc]\n",
    "\n",
    "std_dev_full_mc = np.sqrt(var_probs_full_mc[:n_mc])\n",
    "eps_mc = 1e-10 \n",
    "rel_unc_full_mc = std_dev_full_mc / (mean_probs_full_mc[:n_mc] + eps_mc)\n",
    "gdf_mc[\"mc_std_dev\"] = std_dev_full_mc\n",
    "gdf_mc[\"mc_rel_uncertainty\"] = rel_unc_full_mc\n",
    "\n",
    "out_cols_mc = ['geometry', 'longitude_left', 'latitude_left', 'CV'] \n",
    "out_cols_mc = [col for col in out_cols_mc if col in gdf_mc.columns] \n",
    "out_cols_mc.extend([\"mc_mean_prob\", \"mc_pred_var\", \"mc_std_dev\", \"mc_rel_uncertainty\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6954955164bfe0fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T17:52:23.305820Z",
     "start_time": "2025-06-03T17:44:05.249819Z"
    }
   },
   "outputs": [],
   "source": [
    "gdf_mc[out_cols_mc].to_file(MC_GEOPACKAGE_OUTPUT_PATH, driver=\"GPKG\", layer=\"mc_dropout_total_predictions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
