{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAGI Neural Network Training and Evaluation\n",
    "This notebook implements Tractable Approximate Gaussian Inference (TAGI) for mineral prospectivity mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pytagi\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import psutil\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pytagi.nn import Linear, OutputUpdater, ReLU, Sequential\n",
    "from pytagi import Utils\n",
    "from pytagi.metric import classification_error\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay, classification_report, matthews_corrcoef\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = 'STIXGeneral'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loader Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MineralDataLoader:\n",
    "    def __init__(\n",
    "        self,\n",
    "        features: np.ndarray,\n",
    "        labels: np.ndarray,\n",
    "    ):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.num_samples = features.shape[0]\n",
    "        self.input_dim = features.shape[1]\n",
    "        \n",
    "        utils = Utils()\n",
    "        self.hrc_softmax = utils.get_hierarchical_softmax(num_classes=2)\n",
    "        \n",
    "        y, y_idx, num_enc_obs = utils.label_to_obs(labels=labels, num_classes=2)\n",
    "        \n",
    "        self.y = y.astype(np.float32)\n",
    "        self.y_idx = y_idx.astype(np.int32)\n",
    "    \n",
    "    def create_data_loader(self, batch_size: int, shuffle: bool = True):\n",
    "        indices = np.arange(self.num_samples)\n",
    "        \n",
    "        if shuffle:\n",
    "            np.random.shuffle(indices)\n",
    "        \n",
    "        # Calculate number of batches\n",
    "        num_complete_batches = self.num_samples // batch_size\n",
    "        \n",
    "        for i in range(num_complete_batches):\n",
    "            batch_indices = indices[i * batch_size:(i + 1) * batch_size]\n",
    "            \n",
    "            # Batch data\n",
    "            batch_features = self.features[batch_indices].astype(np.float32)\n",
    "            batch_y = self.y[batch_indices].astype(np.float32)\n",
    "            batch_y_idx = self.y_idx[batch_indices].astype(np.int32)\n",
    "            batch_labels = self.labels[batch_indices]\n",
    "            \n",
    "            yield batch_features, batch_y, batch_y_idx, batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Binary Classification Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassificationMetric:\n",
    "    def __init__(self):\n",
    "        self.num_classes = 2\n",
    "        self.utils = Utils()\n",
    "        self.hrc_softmax = self.utils.get_hierarchical_softmax(num_classes=2)\n",
    "    \n",
    "    def error_rate(self, m_pred: np.ndarray, v_pred: np.ndarray, label: np.ndarray) -> float:\n",
    "        batch_size = m_pred.shape[0] // self.hrc_softmax.len\n",
    "        pred, _ = self.utils.get_labels(\n",
    "            m_pred, v_pred, self.hrc_softmax, self.num_classes, batch_size\n",
    "        )\n",
    "        return classification_error(pred, label)\n",
    "    \n",
    "    def get_predicted_labels(self, m_pred: np.ndarray, v_pred: np.ndarray) -> np.ndarray:\n",
    "        batch_size = m_pred.shape[0] // self.hrc_softmax.len\n",
    "        pred, _ = self.utils.get_labels(\n",
    "            m_pred, v_pred, self.hrc_softmax, self.num_classes, batch_size\n",
    "        )\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prediction-Area Curve Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pa_intersection(\n",
    "    true_positive_rate_values: np.ndarray,\n",
    "    proportion_of_area_values: np.ndarray,\n",
    "    threshold_values: np.ndarray,\n",
    "):\n",
    "    true_positive_area_curve = LineString(np.column_stack((threshold_values, true_positive_rate_values)))\n",
    "    proportion_of_area_values_curve = LineString(np.column_stack((threshold_values, 1 - proportion_of_area_values)))\n",
    "    intersection = true_positive_area_curve.intersection(proportion_of_area_values_curve)\n",
    "    return intersection.x, intersection.y\n",
    "\n",
    "def plot_prediction_area_curves(\n",
    "    true_positive_rate_values: np.ndarray,\n",
    "    proportion_of_area_values: np.ndarray,\n",
    "    threshold_values: np.ndarray,\n",
    "    font_size: int = 10,\n",
    "    fig_size: tuple = (3.333, 3.333)\n",
    "):\n",
    "    x, y = get_pa_intersection(true_positive_rate_values, proportion_of_area_values, threshold_values)\n",
    "\n",
    "    fig = plt.figure(figsize=fig_size)\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(threshold_values, true_positive_rate_values, \"r-\", label=\"Prediction rate\")\n",
    "\n",
    "    ax2.plot(threshold_values, proportion_of_area_values, \"b-\", label=\"Area\")\n",
    "    ax2.plot(x, 1 - y, \"o\", markersize=5, c=\"black\", label=\"Intersection point\")\n",
    "    ax1.set_ylim(0, 1.01)\n",
    "    ax2.set_ylim(-0.01, 1)\n",
    "    ax2.invert_yaxis()\n",
    "\n",
    "    ax1.set_xlabel(\"Threshold\", fontsize=font_size, labelpad=8)\n",
    "    ax1.set_ylabel(\"True positive rate\", color=\"r\", fontsize=font_size, labelpad=8)\n",
    "    ax2.set_ylabel(\"Proportion of area\", color=\"b\", fontsize=font_size, labelpad=8)\n",
    "    \n",
    "    ax1.tick_params(axis='y', colors='r', labelsize=font_size)\n",
    "    ax2.tick_params(axis='y', colors='b', labelsize=font_size)\n",
    "    ax1.tick_params(axis='x', labelsize=font_size)\n",
    "\n",
    "    ax1.annotate(\n",
    "        text=\"TPR: \" + str(round(y, 2)),\n",
    "        xy=(x, y),\n",
    "        xytext=(x + threshold_values.max() * 0.2, y), \n",
    "        arrowprops=dict(\n",
    "            arrowstyle=\"->,head_width=0.3,head_length=0.8\",\n",
    "            color='black',\n",
    "            shrinkA=5, \n",
    "            shrinkB=5  \n",
    "        ),\n",
    "        verticalalignment=\"center\",\n",
    "        fontsize=font_size\n",
    "    )\n",
    "    fig.legend(loc='upper center', bbox_to_anchor=(0.5, 0.40), fontsize=font_size)\n",
    "    \n",
    "    plt.tight_layout(pad=0.5)\n",
    "    return fig, x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. TAGI Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tagi_predictions(net, test_dataloader, metric, batch_size):\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    test_batch_iter = test_dataloader.create_data_loader(batch_size, shuffle=False)\n",
    "    net.eval()\n",
    "    \n",
    "    for x, _, _, label in tqdm(test_batch_iter, desc=\"Generating TAGI Predictions\"):\n",
    "        m_pred, v_pred = net(x)\n",
    "        \n",
    "        # get predictions and probabilities\n",
    "        batch_size_local = m_pred.shape[0] // metric.hrc_softmax.len\n",
    "        pred, probs = metric.utils.get_labels(\n",
    "            m_pred, v_pred, metric.hrc_softmax, metric.num_classes, batch_size_local)\n",
    "        \n",
    "        all_preds.extend(pred)\n",
    "        all_labels.extend(label)\n",
    "        \n",
    "        # handling probability shapes from hierarchical softmax\n",
    "        if len(probs.shape) > 1:\n",
    "            all_probs.extend(probs[:, 1] if probs.shape[1] > 1 else probs.flatten())\n",
    "        else:\n",
    "            if len(probs) == 2*len(pred):\n",
    "                all_probs.extend(probs[1::2])\n",
    "            else:\n",
    "                all_probs.extend(probs)\n",
    "    \n",
    "    return np.array(all_preds), np.array(all_probs), np.array(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Main Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mineral_classification_main(\n",
    "    num_epochs: int = 5,\n",
    "    batch_size: int = 32,\n",
    "    sigma_v: float = 0.5,\n",
    "    is_tracking: bool = False,\n",
    "    use_adasyn: bool = True, \n",
    "    random_state: int = 42,\n",
    "    print_every: int = 10, \n",
    "):\n",
    "    RANDOM_SEED = random_state\n",
    "\n",
    "    process = psutil.Process(os.getpid())\n",
    "    peak_ram = 0\n",
    "\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    random.seed(RANDOM_SEED)\n",
    "\n",
    "    X_train = torch.load('./data/dataset_train.pt').numpy()\n",
    "    y_train = torch.load('./data/mineral_train.pt').numpy()\n",
    "    X_test = torch.load('./data/dataset_test.pt').numpy()\n",
    "    y_test = torch.load('./data/mineral_test.pt').numpy()\n",
    "    \n",
    "    if len(y_train.shape) == 2:\n",
    "        y_train = y_train.ravel()\n",
    "    if len(y_test.shape) == 2:\n",
    "        y_test = y_test.ravel()\n",
    "    \n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "    y_train = y_train.astype(np.int32)\n",
    "    y_test = y_test.astype(np.int32)\n",
    "    \n",
    "    print(f\"Original training set: {X_train.shape[0]} samples, {X_train.shape[1]} features\")\n",
    "    print(f\"Original training class distribution: {np.bincount(y_train)}\")\n",
    "    \n",
    "    # apply ADASYN \n",
    "    if use_adasyn:\n",
    "        adasyn = ADASYN(random_state=RANDOM_SEED)\n",
    "        X_train, y_train = adasyn.fit_resample(X_train, y_train)\n",
    "        print(f\"After ADASYN - training set: {X_train.shape[0]} samples, {X_train.shape[1]} features\")\n",
    "        print(f\"After ADASYN - training class distribution: {np.bincount(y_train)}\")\n",
    "    \n",
    "    print(f\"Testing set: {X_test.shape[0]} samples, {X_test.shape[1]} features\")\n",
    "    print(f\"Testing class distribution: {np.bincount(y_test)}\")\n",
    "    \n",
    "    train_dataloader = MineralDataLoader(X_train, y_train)\n",
    "    test_dataloader = MineralDataLoader(X_test, y_test)\n",
    "    \n",
    "    metric = BinaryClassificationMetric()\n",
    "\n",
    "    input_dim = X_train.shape[1]\n",
    "\n",
    "    MINERAL_FNN = Sequential(\n",
    "        Linear(input_dim, 32),\n",
    "        ReLU(),  \n",
    "        Linear(32, 32),\n",
    "        ReLU(),\n",
    "        Linear(32, 1),\n",
    "    )\n",
    "    \n",
    "    net = MINERAL_FNN\n",
    "    if pytagi.cuda.is_available():\n",
    "        net.to_device(\"cuda\")\n",
    "    else:\n",
    "        net.set_threads(8)\n",
    "\n",
    "    def count_all_params(item):\n",
    "        if isinstance(item, (int, float)):\n",
    "            return 1\n",
    "        elif isinstance(item, (list, tuple)):\n",
    "            return sum(count_all_params(sub_item) for sub_item in item)\n",
    "        return 0\n",
    "\n",
    "    all_model_params = net.parameters()\n",
    "    total_params = count_all_params(all_model_params)\n",
    "\n",
    "    print(f\"TAGI - Total trainable parameters: {total_params:,}\")\n",
    "\n",
    "    out_updater = OutputUpdater(net.device)\n",
    "\n",
    "    ### TRAINING\n",
    "    error_rates = []\n",
    "    train_error_rates = []  \n",
    "    val_error_rates = []   \n",
    "    test_error_rates = []   \n",
    "    epoch_list = []     \n",
    "\n",
    "    process = psutil.Process(os.getpid())\n",
    "    overall_peak_ram_mb = 0 \n",
    "    epoch_durations_list = []  \n",
    "    \n",
    "    var_y = np.full(\n",
    "        (batch_size * metric.hrc_softmax.num_obs,), sigma_v**2, dtype=np.float32\n",
    "    )\n",
    "    pbar = tqdm(range(num_epochs), desc=\"Training Progress\")\n",
    "    epoch_durations_list = []\n",
    "    print_var = True\n",
    "    \n",
    "    for epoch in pbar:\n",
    "        epoch_start_time = time.time()\n",
    "        epoch_list.append(epoch + 1)\n",
    "        peak_ram_in_epoch_mb = 0\n",
    "        \n",
    "        batch_iter = train_dataloader.create_data_loader(batch_size=batch_size)\n",
    "        net.train()\n",
    "        epoch_errors = []\n",
    "        \n",
    "        for x, y, y_idx, label in batch_iter:\n",
    "            m_pred, v_pred = net(x)\n",
    "            if print_var:\n",
    "                print(\n",
    "                    \"Prior predictive -> E[v_pred] = \",\n",
    "                    np.average(v_pred),\n",
    "                    \"+-\",\n",
    "                    np.std(v_pred),\n",
    "                )\n",
    "                print_var = False\n",
    "\n",
    "            actual_batch_size = x.shape[0]\n",
    "            if actual_batch_size != batch_size:\n",
    "                var_y = np.full(\n",
    "                    (actual_batch_size * metric.hrc_softmax.num_obs,), sigma_v**2, dtype=np.float32\n",
    "                )\n",
    "\n",
    "            out_updater.update_using_indices(\n",
    "                output_states=net.output_z_buffer,\n",
    "                mu_obs=y,\n",
    "                var_obs=var_y,\n",
    "                selected_idx=y_idx,\n",
    "                delta_states=net.input_delta_z_buffer,\n",
    "            )\n",
    "\n",
    "            net.backward()\n",
    "            net.step()\n",
    "\n",
    "            batch_error = metric.error_rate(m_pred, v_pred, label)\n",
    "            error_rates.append(batch_error)\n",
    "            epoch_errors.append(batch_error)\n",
    "\n",
    "            current_ram_mb = process.memory_info().rss / (1024 ** 2)\n",
    "            peak_ram_in_epoch_mb = max(peak_ram_in_epoch_mb, current_ram_mb)\n",
    "            overall_peak_ram_mb = max(overall_peak_ram_mb, current_ram_mb)\n",
    "\n",
    "        avg_train_error = sum(epoch_errors) / len(epoch_errors) if epoch_errors else 0\n",
    "        train_error_rates.append(avg_train_error * 100) \n",
    "        \n",
    "        should_print = (epoch + 1) % print_every == 0 or epoch == num_epochs - 1\n",
    "\n",
    "        # Testing\n",
    "        correct = 0\n",
    "        num_samples = 0\n",
    "        test_batch_iter = test_dataloader.create_data_loader(batch_size, shuffle=False)\n",
    "        net.eval()\n",
    "        for x, _, _, label in test_batch_iter:\n",
    "            m_pred, v_pred = net(x)\n",
    "            pred = metric.get_predicted_labels(m_pred, v_pred)\n",
    "            correct += np.sum(pred == label)\n",
    "            num_samples += len(label)\n",
    "\n",
    "        test_error_rate = (1.0 - correct / num_samples) * 100\n",
    "        test_error_rates.append(test_error_rate) \n",
    "        val_error_rates.append(test_error_rate)  \n",
    "        \n",
    "        if should_print:\n",
    "            pbar.set_description(\n",
    "                f\"Epoch {epoch + 1}/{num_epochs} | training error: {avg_train_error*100:.7f}% | test error: {test_error_rate:.7f}%\",\n",
    "                refresh=True,\n",
    "            )\n",
    "\n",
    "        current_epoch_duration = time.time() - epoch_start_time\n",
    "        epoch_durations_list.append(current_epoch_duration)\n",
    "        print(f\"Epoch {epoch+1} completed in {current_epoch_duration:.2f} seconds. Peak RAM in Epoch: {peak_ram_in_epoch_mb:.2f} MB\")\n",
    "    \n",
    "    print(f\"Final test error rate: {test_error_rate:.5f}%\")\n",
    "\n",
    "    model_save_path = 'tagi_adasyn_v1.pth'\n",
    "    torch.save(net.state_dict(), model_save_path)\n",
    "    print(f\"Trained TAGI model saved to {model_save_path}\")\n",
    "    \n",
    "    return {\n",
    "            \"net\": net,\n",
    "            \"train_dataloader\": train_dataloader,\n",
    "            \"test_dataloader\": test_dataloader,\n",
    "            \"metric\": metric,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"train_error_rates\": train_error_rates, \n",
    "            \"test_error_rates\": test_error_rates,   \n",
    "            \"epoch_durations\": epoch_durations_list,\n",
    "            \"peak_ram_mb\": overall_peak_ram_mb,\n",
    "            \"epochs_list\": epoch_list\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results = mineral_classification_main(\n",
    "    num_epochs=100,     \n",
    "    batch_size=32,   \n",
    "    sigma_v=5,\n",
    "    use_adasyn=True,\n",
    "    print_every=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Final Summary ---\")\n",
    "model_trained = training_results[\"net\"]\n",
    "epoch_durations_list = training_results[\"epoch_durations\"]\n",
    "peak_ram_mb = training_results[\"peak_ram_mb\"] \n",
    "\n",
    "# Average time per epoch with std\n",
    "if epoch_durations_list:\n",
    "    avg_time = np.mean(epoch_durations_list)\n",
    "    std_time = np.std(epoch_durations_list)\n",
    "    print(f\"TAGI - Average time per epoch: {avg_time:.2f} Â± {std_time:.2f} seconds\")\n",
    "\n",
    "# Overall peak RAM\n",
    "print(f\"TAGI - Overall Peak RAM: {peak_ram_mb:.2f} MB\")\n",
    "\n",
    "# Number of parameters\n",
    "def count_all_params(item):\n",
    "    if isinstance(item, (int, float)): return 1\n",
    "    elif isinstance(item, (list, tuple)): return sum(count_all_params(sub_item) for sub_item in item)\n",
    "    return 0\n",
    "total_params = count_all_params(model_trained.parameters())\n",
    "print(f\"TAGI - Total trainable parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Load Trained Model and Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the saved model\n",
    "input_dim = 173  \n",
    "net = Sequential(\n",
    "    Linear(input_dim, 32),\n",
    "    ReLU(),\n",
    "    Linear(32, 32),\n",
    "    ReLU(),\n",
    "    Linear(32, 1),\n",
    ")\n",
    "\n",
    "model_save_path = 'tagi_adasyn_v1.pth'\n",
    "net.load_state_dict(torch.load(model_save_path))\n",
    "net.eval()\n",
    "\n",
    "batch_size = 32\n",
    "metric = BinaryClassificationMetric()\n",
    "\n",
    "X_test = torch.load('./data/dataset_test.pt').numpy().astype(np.float32)\n",
    "y_test = torch.load('./data/mineral_test.pt').numpy().ravel().astype(np.int32)\n",
    "\n",
    "test_dataloader = MineralDataLoader(X_test, y_test)\n",
    "all_preds, all_probs, all_labels = get_tagi_predictions(net, test_dataloader, metric, batch_size)\n",
    "\n",
    "np.save('tagi_all_preds.npy', all_preds)\n",
    "np.save('tagi_all_probs.npy', all_probs)\n",
    "np.save('tagi_all_labels.npy', all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_probs = np.load('tagi_all_probs.npy')\n",
    "all_labels = np.load('tagi_all_labels.npy')\n",
    "\n",
    "fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'TAGI ROC Curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\
